{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_project_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suite2p import run_s2p\n",
    "import imagej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scyjava_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to your Fiji installation that includes `ImageJ-win64.exe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiji_path = 'fiji'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scyjava_config.add_options('-Xmx2g')\n",
    "ij = imagej.init(fiji_path)\n",
    "ij.getVersion()\n",
    "ij.ui().showUI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select directory containng `.h5` and `.nd2` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dir = select_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fish_dir)\n",
    "#nd2_files = list(filter(lambda x: \"wholebrain\" not in x, list_files(fish_dir, extension='nd2')))\n",
    "nd2_files = list(filter(lambda x: \"wholebrain\" not in x, list_files(fish_dir, extension='tif')))\n",
    "h5_files = list_files(fish_dir, extension='h5')\n",
    "\n",
    "processed_dir = fish_dir + '/processed'\n",
    "avi_dir = processed_dir + '/avi'\n",
    "raw_tif_dir = processed_dir + '/raw tif'\n",
    "combined_tif_dir = processed_dir + '/combined tif/'\n",
    "intensity_dir = processed_dir + '/intensity'\n",
    "registered_tif_dir = processed_dir + '/registered tif'\n",
    "neural_dir = processed_dir + '/neural'\n",
    "behavior_dir = processed_dir + '/behavior'\n",
    "\n",
    "for directory in [processed_dir, avi_dir, raw_tif_dir, combined_tif_dir,\n",
    "                  intensity_dir, registered_tif_dir, neural_dir, behavior_dir]:\n",
    "    create_directory(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro for converting `.nd2` image data to `.tif` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_to_tif = \"\"\"\n",
    "#@ String nd2_path\n",
    "#@ String save_path\n",
    "setBatchMode(true);\n",
    "run(\"Bio-Formats Importer\", \"open=[\" + nd2_path + \"] autoscale color_mode=Default rois_import=[ROI manager] view=Hyperstack stack_order=XYCZT\");\n",
    "//run(\"Rotate 90 Degrees Left\");\n",
    "run(\"8-bit\");\n",
    "saveAs(\"Tiff\", save_path);\n",
    "run(\"Close All\");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_tif_files = list(map(lambda x: x.replace('nd2', 'tif').replace(fish_dir, raw_tif_dir), nd2_files))\n",
    "raw_tif_files = list(map(lambda x: x.replace('nd2', 'tif').replace(fish_dir, raw_tif_dir), nd2_files))\n",
    "\n",
    "for nd2_file, tif_file  in zip(nd2_files, raw_tif_files):\n",
    "    args = {\n",
    "        'nd2_path': nd2_file,\n",
    "        'save_path': tif_file\n",
    "    }\n",
    "    ij.py.run_script('ijm', nd2_to_tif, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro for combining multiple `.tif` files into one `.tif` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_tif = \"\"\"\n",
    "#@ String[] tif_files\n",
    "#@ String save_directory\n",
    "#@output String slices\n",
    "setBatchMode(true);\n",
    "open(tif_files[0]);\n",
    "image1 = getTitle();\n",
    "slices = toString(nSlices);\n",
    "\n",
    "for (i = 1; i < tif_files.length; ++i) {\n",
    "    open(tif_files[i]);\n",
    "    image2 = getTitle();\n",
    "    slices = slices + \" \" + toString(nSlices);\n",
    "    run(\"Concatenate...\", \"open image1=\" + image1 + \" image2=\"+ image2);\n",
    "    image1 = getTitle();\n",
    "}\n",
    "saveAs(\"Tiff\", save_directory + \"combined.tif\");\n",
    "run(\"Close All\");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'tif_files': raw_tif_files,\n",
    "    'save_directory': combined_tif_dir + '/'\n",
    "}\n",
    "\n",
    "slices = ij.py.run_script('ijm', combine_tif, args).getOutput('slices')\n",
    "slices = list(map(lambda x: int(x), slices.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = run_s2p.default_ops()\n",
    "ops['batch_size'] = 5000\n",
    "ops['roidetect'] = False\n",
    "ops['reg_tif'] = True\n",
    "ops['save_folder'] = processed_dir\n",
    "ops['reg_tif'] = True\n",
    "\n",
    "db = {\n",
    "      'h5py': [],\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False,\n",
    "      'data_path': [combined_tif_dir],                     \n",
    "      'subfolders': [], 'reg_tif': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro for watershed segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = \"\"\"\n",
    "#@ String image_path\n",
    "\n",
    "open(image_path);\n",
    "window_name = getTitle();\n",
    "output_directory = replace(image_path, window_name, \"\");\n",
    "run(\"Z Project...\", \"projection=[Average Intensity]\");\n",
    "selectWindow(window_name);\n",
    "run(\"Close\");\n",
    "avg = getTitle();\n",
    "run(\"8-bit\");\n",
    "setTool(\"rectangle\");\n",
    "waitForUser(\"Pause\", \"Draw midbox\"); // Ask for input ROI\n",
    "saveAs(\"XY Coordinates\", output_directory + \"Midline.txt\");\n",
    "run(\"Select None\");\n",
    "setTool(\"polygon\");\n",
    "waitForUser(\"Pause\", \"Draw a mask\");\n",
    "run(\"Create Mask\");\n",
    "saveAs(\"Tiff\", output_directory + \"Mask.tif\");\n",
    "imageCalculator(\"AND create stack\", avg , \"Mask.tif\");\n",
    "run(\"Median...\", \"radius=1 stack\");\n",
    "run(\"Enhance Contrast...\", \"saturated=0.3 normalize\");\n",
    "run(\"Morphological Filters\", \"operation=[White Top Hat] element=Disk radius=5\");\n",
    "run(\"Invert\");\n",
    "run(\"Watershed Segmentation\");\n",
    "waitForUser(\"Pause\", \"Check results\");\n",
    "saveAs(\"Tiff\", output_directory + \"label.tif\");\n",
    "run(\"Analyze Regions\", \"area perimeter circularity centroid \");\n",
    "saveAs(\"Results\", output_directory + \"label-Morphometry.csv\");\n",
    "run(\"Close All\");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_tif = processed_dir + '/plane0/reg_tif/file000_chan0.tif'\n",
    "\n",
    "args = {\n",
    "    'image_path': registered_tif,\n",
    "}\n",
    "ij.py.run_script('ijm', segmentation, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro for separating registered combined `.tif` imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate = \"\"\"\n",
    "#@ String combined_tif_path\n",
    "#@ String save_path\n",
    "#@ String[] tif_names\n",
    "#@ Integer[] slices\n",
    "setBatchMode(true);\n",
    "open(combined_tif_path);\n",
    "main_window = getTitle();\n",
    "folder = replace(combined_tif_path, main_window, \"\");\n",
    "save_folder = folder + \"results\\\\\";\n",
    "\n",
    "File.makeDirectory(replace(combined_tif_path, main_window, \"results\"));\n",
    "\n",
    "for (i = 0; i < slices.length; ++i) {\n",
    "    if (i < slices.length - 1) {\n",
    "        run(\"Make Substack...\", \"delete slices=1-\" + slices[i]);\n",
    "        curr_win = getTitle();\n",
    "    }\n",
    "    run(\"8-bit\");\n",
    "    saveAs(\"Tiff\", save_path + tif_names[i]);\n",
    "    run(\"Close\");\n",
    "}\n",
    "run(\"Close All\");\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_names = list(map(lambda x: x.split('/')[-1], raw_tif_files))\n",
    "\n",
    "args = {\n",
    "    'combined_tif_path': processed_dir + '/plane0/reg_tif/file000_chan0.tif',\n",
    "    'save_path': registered_tif_dir + '/',\n",
    "    'tif_names': tif_names,\n",
    "    'slices': slices\n",
    "}\n",
    "ij.py.run_script('ijm', separate, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro for getting the intensities of ROIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_tif_dir)\n",
    "get_intensity = \"\"\"\n",
    "setBatchMode(true)\n",
    "#@ String label\n",
    "#@ String save_folder\n",
    "#@ String[] file_list\n",
    "setBatchMode(true);\n",
    "for (i = 0; i < file_list.length; ++i) {\n",
    "    temp = split(file_list[i], \"/\");\n",
    "    getInt(file_list[i], label, save_folder + replace(temp[temp.length - 1], \".tif\", \"/\"));\n",
    "}\n",
    "\n",
    "function getInt(image, label, save_folder) {\n",
    "    if (!File.exists(save_folder)) {\n",
    "        File.makeDirectory(save_folder);\n",
    "    }\n",
    "    open(label);\n",
    "    label_window = replace(getTitle(), \".tif\", \"\");\n",
    "    open(image);\n",
    "    image = getTitle();\n",
    "    run(\"8-bit\");\n",
    "    for(i = 1; i <= nSlices; ++i) {\n",
    "        setSlice(i); // start from first frame\n",
    "        run(\"Duplicate...\", \"use\"); // isolate the frame\n",
    "        current_slice = getTitle();\n",
    "        print(current_slice);\n",
    "        curr = replace(current_slice, \".tif\", \"\");\n",
    "        //print(curr);\n",
    "        run(\"Intensity Measurements 2D/3D\", \"input=\" + curr + \" labels=\" + label_window +  \" mean\");\n",
    "        saveAs(\"Results\", save_folder + \"int_t\" + toString(i) + \".csv\");\n",
    "        run(\"Close\");\n",
    "        selectWindow(current_slice);\n",
    "        run(\"Close\");\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_files(registered_tif_dir)\n",
    "\n",
    "label = processed_dir + '/plane0/reg_tif/label.tif'\n",
    "\n",
    "args = {\n",
    "    'label': label,\n",
    "    'save_folder': intensity_dir + '/',\n",
    "    'file_list': list_files(registered_tif_dir),\n",
    "}\n",
    "ij.py.run_script('ijm', get_intensity, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `.h5` files to `.avi` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dir = 'E:\\\\new folder\\\\002 ANALYSIS\\\\4v6_4v2\\\\2P032-A4\\\\'\n",
    "h5_files = list_files(fish_dir, extension='h5')\n",
    "avi_dir = fish_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main = 'E:\\\\new folder\\\\002 ANALYSIS\\\\compare PC in 2 dots\\\\' # added\n",
    "#fish = ['2P021-A6', '2P022-A7', '2P026-A2', '2P027-A2', '2P029-A2', # added\n",
    "#            '2P032-A4', '2P035-A1', '2P035-A2', '2P035-A3', '2P035-A4',\n",
    "#           '2P035-A5', '2P042-A3', '2P044-A1']\n",
    "\n",
    "#for ith in range(12,13):# added\n",
    "#    fish_dir = main + fish[ith] # added\n",
    "#processed_dir = fish_dir + '/processed'\n",
    "#    avi_dir = processed_dir + '/avi' # added\n",
    "fps = 100\n",
    " #   fps = 300 # added\n",
    " #   if ith == 10 or ith == 11: # added\n",
    " #       fps = 100 # added\n",
    " #   for directory in [processed_dir, avi_dir]: # added\n",
    " #       create_directory(directory) # added\n",
    "    \n",
    "h5_files = list_files(fish_dir, extension='h5')\n",
    "for hdf_path in h5_files:\n",
    "    filename, file_extension = os.path.splitext(hdf_path)\n",
    "    vid = h5py.File(hdf_path, 'r')\n",
    "    keys = vid.keys()\n",
    "    images = []\n",
    "    dotstop = ''\n",
    "    for i in keys:\n",
    "        ind = re.findall('\\d+', i)\n",
    "        images.append(int(ind[0]))\n",
    "    images = sorted(images)\n",
    "    video_name = filename + dotstop + '.avi'\n",
    "    height, width = vid[list(keys)[0]][:].shape\n",
    "\n",
    "    #video = cv2.VideoWriter(os.path.splitext(hdf_path)[0].replace(fish_dir , avi_dir) + '.avi',\n",
    "                            #cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps, (width, height), isColor=False)\n",
    "    \n",
    "    video = cv2.VideoWriter(os.path.splitext(hdf_path)[0].replace(fish_dir , avi_dir) + '.avi', 0, fps, (width, height), isColor=False)\n",
    "\n",
    "    for im in tqdm(sorted(keys, key=lambda x: int(x))):\n",
    "        img = vid[im][:]\n",
    "        video.write(img)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avi_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and process `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = pd.read_csv(processed_dir + '/plane0/reg_tif/label-Morphometry.csv')\n",
    "neurons = np.array(morphology[(morphology.Area < 200) & (morphology.Area > 15) & (morphology.Circularity > 0.5) & (morphology.Circularity < 1.5)].Label)\n",
    "\n",
    "for trial_dir in list_directories(intensity_dir):\n",
    "    split = trial_dir.split('/')[-1].replace('-', '_').replace('.', '_').split('_')\n",
    "    fish_trial = split[1] + '-' + split[-1]\n",
    "    df = pd.concat([pd.read_csv(int_file).set_index('Label').rename(\n",
    "                   columns={'Mean': int(int_file.split('t')[-1].split('.')[0]) - 1})\n",
    "                   for int_file in list_files(trial_dir)], axis=1)\n",
    "\n",
    "    df = df.reindex(sorted(df.columns), axis=1).transpose()\n",
    "    for t in df:\n",
    "        df[t] = (df[t] - df[t].quantile(.25)) / df[t].quantile(.25)\n",
    "    new_df = df[neurons].transpose()\n",
    "    new_df.to_csv(neural_dir + '/' + fish_trial + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Getting eye angles from `.avi` files using `zfish_track`\n",
    "Get `zfish_track` from <https://github.com/kclamar/zfish-track>, or\n",
    "\n",
    "Install with `pip`: `pip install git+git://github.com/kclamar/zfish-track.git`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/kclamar/zfish-track.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zfish_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = list_files(avi_dir, '.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_path in videos:\n",
    "    video_name = os.path.split(video_path)[1]\n",
    "    split = video_name.replace('-', '_').replace('.', '_').split('_')\n",
    "    fish_trial = split[1] + '-' + split[-2]\n",
    "    e, s, r = zfish_track.gui_analyze(video_path, behavior_dir + '/' + fish_trial + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff().iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, a = signal.ellip(4, 0.01, 120, 0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.filtfilt(b, a, np.array(df['left']), method=\"gust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onset_frames = [2174, 2076, 2170, 2137, 1994, 2957]\n",
    "for j, csv in enumerate(list_files(behavior_dir)):\n",
    "    df = pd.read_csv(csv, index_col=0)\n",
    "    new_df = df.copy()\n",
    "    for i in new_df:\n",
    "        new_df[i] = signal.filtfilt(b, a, np.array(df[i]), method=\"gust\")\n",
    "    new_df.plot()\n",
    "    plt.axvline(onset_frames[j], c='C2')\n",
    "    plt.title(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (WIP) Manually enter the prey capture onset time for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_trials = []\n",
    "onset_time = []\n",
    "for i, video_path in enumerate(videos):\n",
    "    video_name = os.path.split(video_path)[1]\n",
    "    split = video_name.replace('-', '_').replace('.', '_').split('_')\n",
    "    fish_trial = split[1] + '-' + split[-2]\n",
    "    fish_trials.append(fish_trial)\n",
    "    onset_time.append(onset_frames[i])\n",
    "pd.DataFrame(onset_time, index=fish_trials, columns=['onset time']).to_csv(f'{processed_dir}/onset_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
